{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Downloading data from public drive link"
      ],
      "metadata": {
        "id": "-GwileLtTjji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1EA2FaU5Qwo9z7kJB0J4tMhIkM2DU8MXk\n",
        "!gdown 1i9TX8Y3cTBhl-74aEnbtgJm14BkP9AJI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THhOaM7j-wfG",
        "outputId": "effaf42b-0e33-4152-c2d5-2cfdb474818f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1EA2FaU5Qwo9z7kJB0J4tMhIkM2DU8MXk\n",
            "To: /content/air_properties_data.xlsx\n",
            "100% 386k/386k [00:00<00:00, 19.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1i9TX8Y3cTBhl-74aEnbtgJm14BkP9AJI\n",
            "To: /content/power_data.xlsx\n",
            "100% 366k/366k [00:00<00:00, 20.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "i0yE4GYUNiY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8f2aa47-f937-417a-cdd8-1e521394c71b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Power  Air Density  Wind Speed           Timestamp\n",
            "0  0.378601     0.000000    0.369528 2022-01-01 01:00:00\n",
            "1  0.433128     0.000071    0.437079 2022-01-01 02:00:00\n",
            "2  0.624486     0.000141    0.450589 2022-01-01 03:00:00\n",
            "3  0.662551     0.000212    0.338005 2022-01-01 04:00:00\n",
            "4  0.339506     0.000282    0.333501 2022-01-01 05:00:00\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "air_properties_data = pd.read_excel(\"air_properties_data.xlsx\")\n",
        "power_data = pd.read_excel(\"power_data.xlsx\")\n",
        "\n",
        "# Merge datasets based on timestamp\n",
        "data = pd.merge(power_data, air_properties_data, on=\"Timestamp\")\n",
        "data.rename(columns = {'power':'Power', 'WindSpeed':'Wind Speed', 'Unnamed: 0_y':'Air Density' }, inplace = True)\n",
        "# Handle missing values\n",
        "data = data.dropna()\n",
        "\n",
        "# Normalize features\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(data[['Power', 'Air Density', 'Wind Speed']])\n",
        "\n",
        "# Convert to DataFrame\n",
        "data_scaled_df = pd.DataFrame(data_scaled, columns=['Power', 'Air Density', 'Wind Speed'])\n",
        "data_scaled_df['Timestamp'] = data['Timestamp']\n",
        "\n",
        "\n",
        "print(data_scaled_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering:"
      ],
      "metadata": {
        "id": "615nP3ojRXND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_scaled_df['Hour'] = data_scaled_df['Timestamp'].dt.hour\n",
        "data_scaled_df['DayOfWeek'] = data_scaled_df['Timestamp'].dt.dayofweek\n",
        "data_scaled_df['Month'] = data_scaled_df['Timestamp'].dt.month\n",
        "print(data_scaled_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qWAVGZDRUcp",
        "outputId": "eb84c1e2-4dff-43bf-de05-e96916dc0c55"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Power  Air Density  Wind Speed           Timestamp  Hour  DayOfWeek  \\\n",
            "0  0.378601     0.000000    0.369528 2022-01-01 01:00:00     1          5   \n",
            "1  0.433128     0.000071    0.437079 2022-01-01 02:00:00     2          5   \n",
            "2  0.624486     0.000141    0.450589 2022-01-01 03:00:00     3          5   \n",
            "3  0.662551     0.000212    0.338005 2022-01-01 04:00:00     4          5   \n",
            "4  0.339506     0.000282    0.333501 2022-01-01 05:00:00     5          5   \n",
            "\n",
            "   Month  \n",
            "0      1  \n",
            "1      1  \n",
            "2      1  \n",
            "3      1  \n",
            "4      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Selection and Training:"
      ],
      "metadata": {
        "id": "sE78XJ3ESuu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "filtered_df = data_scaled_df[data_scaled_df['Timestamp'].dt.date.isin([pd.Timestamp('2023-01-15').date()])]\n",
        "filtered_df = filtered_df.drop(columns=['Timestamp'])\n",
        "special_date = np.array(filtered_df)\n",
        "special_date_label = np.array(filtered_df.iloc[23, 0])\n",
        ""
      ],
      "metadata": {
        "id": "aNP63zoQX7C6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_scaled_df = data_scaled_df.drop(columns=['Timestamp'])"
      ],
      "metadata": {
        "id": "9zKUS9_8YjKl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "train_data, test_data = train_test_split(data_scaled_df, test_size=0.2, shuffle=False)\n",
        "\n",
        "# Prepare input sequences and target values\n",
        "sequence_length = 24  # Number of previous hours to consider\n",
        "X_train, y_train = [], []\n",
        "X_test, y_test = [], []\n",
        "\n",
        "for i in range(sequence_length, len(train_data)):\n",
        "    X_train.append(train_data.iloc[i - sequence_length:i])\n",
        "    y_train.append(train_data.iloc[i, 0])  # Power column\n",
        "\n",
        "for i in range(sequence_length, len(test_data)):\n",
        "    X_test.append(test_data.iloc[i - sequence_length:i])\n",
        "    y_test.append(test_data.iloc[i, 0])  # Power column\n",
        "\n",
        "# Convert to arrays\n",
        "X_train = np.array(X_train, np.float32)\n",
        "y_train = np.array(y_train, np.float32)\n",
        "X_test = np.array(X_test, np.float32)\n",
        "y_test = np.array(y_test, np.float32)\n",
        "\n",
        "print(X_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF0DB8hMRdIO",
        "outputId": "c11ddb1d-95f9-43c0-9c19-7d5dc8cb0836"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11296, 24, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mean_squared_error')\n",
        "\n",
        "# Callbacks\n",
        "cb_e = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=4)\n",
        "cb_r = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=0.1)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), callbacks=[cb_e, cb_r])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgpfIl-woSJz",
        "outputId": "fafde0f1-d6d4-455d-8a38-fe86c1ac3e09"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "353/353 [==============================] - 11s 18ms/step - loss: 0.0695 - val_loss: 0.0398 - lr: 1.0000e-04\n",
            "Epoch 2/50\n",
            "353/353 [==============================] - 6s 16ms/step - loss: 0.0332 - val_loss: 0.0233 - lr: 1.0000e-04\n",
            "Epoch 3/50\n",
            "353/353 [==============================] - 6s 17ms/step - loss: 0.0227 - val_loss: 0.0171 - lr: 1.0000e-04\n",
            "Epoch 4/50\n",
            "353/353 [==============================] - 5s 15ms/step - loss: 0.0178 - val_loss: 0.0146 - lr: 1.0000e-04\n",
            "Epoch 5/50\n",
            "353/353 [==============================] - 6s 18ms/step - loss: 0.0150 - val_loss: 0.0146 - lr: 1.0000e-04\n",
            "Epoch 6/50\n",
            "353/353 [==============================] - 5s 15ms/step - loss: 0.0130 - val_loss: 0.0108 - lr: 1.0000e-04\n",
            "Epoch 7/50\n",
            "353/353 [==============================] - 6s 18ms/step - loss: 0.0117 - val_loss: 0.0097 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "353/353 [==============================] - 5s 15ms/step - loss: 0.0105 - val_loss: 0.0088 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "353/353 [==============================] - 6s 18ms/step - loss: 0.0096 - val_loss: 0.0079 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "353/353 [==============================] - 5s 15ms/step - loss: 0.0090 - val_loss: 0.0075 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "353/353 [==============================] - 6s 16ms/step - loss: 0.0085 - val_loss: 0.0069 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "353/353 [==============================] - 6s 16ms/step - loss: 0.0080 - val_loss: 0.0067 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "353/353 [==============================] - 5s 15ms/step - loss: 0.0077 - val_loss: 0.0063 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "353/353 [==============================] - 6s 18ms/step - loss: 0.0073 - val_loss: 0.0068 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "353/353 [==============================] - 5s 15ms/step - loss: 0.0071 - val_loss: 0.0058 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "353/353 [==============================] - 7s 18ms/step - loss: 0.0068 - val_loss: 0.0056 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "353/353 [==============================] - 6s 17ms/step - loss: 0.0064 - val_loss: 0.0055 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "353/353 [==============================] - 7s 20ms/step - loss: 0.0061 - val_loss: 0.0048 - lr: 1.0000e-04\n",
            "Epoch 19/50\n",
            "353/353 [==============================] - 7s 19ms/step - loss: 0.0058 - val_loss: 0.0047 - lr: 1.0000e-04\n",
            "Epoch 20/50\n",
            "353/353 [==============================] - 6s 18ms/step - loss: 0.0056 - val_loss: 0.0046 - lr: 1.0000e-04\n",
            "Epoch 21/50\n",
            "353/353 [==============================] - 5s 14ms/step - loss: 0.0052 - val_loss: 0.0045 - lr: 1.0000e-04\n",
            "Epoch 22/50\n",
            "353/353 [==============================] - 6s 18ms/step - loss: 0.0050 - val_loss: 0.0042 - lr: 1.0000e-04\n",
            "Epoch 23/50\n",
            "353/353 [==============================] - 5s 15ms/step - loss: 0.0047 - val_loss: 0.0041 - lr: 1.0000e-04\n",
            "Epoch 24/50\n",
            "353/353 [==============================] - 6s 18ms/step - loss: 0.0045 - val_loss: 0.0038 - lr: 1.0000e-04\n",
            "Epoch 25/50\n",
            "353/353 [==============================] - 5s 15ms/step - loss: 0.0043 - val_loss: 0.0036 - lr: 1.0000e-04\n",
            "Epoch 26/50\n",
            "353/353 [==============================] - 5s 15ms/step - loss: 0.0041 - val_loss: 0.0036 - lr: 1.0000e-04\n",
            "Epoch 27/50\n",
            "353/353 [==============================] - 6s 18ms/step - loss: 0.0039 - val_loss: 0.0035 - lr: 1.0000e-04\n",
            "Epoch 28/50\n",
            "353/353 [==============================] - 5s 16ms/step - loss: 0.0038 - val_loss: 0.0033 - lr: 1.0000e-04\n",
            "Epoch 29/50\n",
            "353/353 [==============================] - 7s 19ms/step - loss: 0.0037 - val_loss: 0.0034 - lr: 1.0000e-04\n",
            "Epoch 30/50\n",
            "353/353 [==============================] - 5s 13ms/step - loss: 0.0036 - val_loss: 0.0032 - lr: 1.0000e-04\n",
            "Epoch 31/50\n",
            "353/353 [==============================] - 5s 15ms/step - loss: 0.0034 - val_loss: 0.0035 - lr: 1.0000e-04\n",
            "Epoch 32/50\n",
            "353/353 [==============================] - 5s 13ms/step - loss: 0.0034 - val_loss: 0.0034 - lr: 1.0000e-04\n",
            "Epoch 33/50\n",
            "353/353 [==============================] - 4s 13ms/step - loss: 0.0034 - val_loss: 0.0030 - lr: 1.0000e-04\n",
            "Epoch 34/50\n",
            "353/353 [==============================] - 5s 15ms/step - loss: 0.0033 - val_loss: 0.0034 - lr: 1.0000e-04\n",
            "Epoch 35/50\n",
            "353/353 [==============================] - 5s 14ms/step - loss: 0.0033 - val_loss: 0.0030 - lr: 1.0000e-04\n",
            "Epoch 36/50\n",
            "353/353 [==============================] - 6s 17ms/step - loss: 0.0032 - val_loss: 0.0031 - lr: 1.0000e-04\n",
            "Epoch 37/50\n",
            "353/353 [==============================] - 6s 17ms/step - loss: 0.0032 - val_loss: 0.0031 - lr: 1.0000e-04\n",
            "Epoch 38/50\n",
            "353/353 [==============================] - 5s 15ms/step - loss: 0.0031 - val_loss: 0.0030 - lr: 1.0000e-04\n",
            "Epoch 39/50\n",
            "353/353 [==============================] - 6s 17ms/step - loss: 0.0031 - val_loss: 0.0031 - lr: 1.0000e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7e5615cc1810>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.expand_dims(special_date, 0).shape)\n",
        "y_pred = model.predict(np.expand_dims(special_date, 0))\n",
        "print('Power consumption of 2023-01-15  is {:.2f}, predicted value is {:.2f}'.format(special_date_label, y_pred[0][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYbt1AQaZcZz",
        "outputId": "e85e64ee-2cc5-49fd-e44b-45029e0e1766"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 24, 6)\n",
            "1/1 [==============================] - 1s 507ms/step\n",
            "Power consumption of 2023-01-15  is 0.96, predicted value is 0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Communication and Interpretation: Imagine you have a manager who doesnâ€™t know much about\n",
        "data. How would you describe and summarize your Project birefly without missing any steps?**\n",
        "\n",
        "Hello! I'd like to share a summary of the Wind Energy Power Production Prediction project I've been working on. Our goal was to build a model that can forecast the amount of power a wind plant will produce in the future. This is crucial for effective planning and decision-making in the wind energy field.\n",
        "\n",
        "First, I collected data on important factors affecting power production, such as air density and wind speed. I combined this data with historical power production records to create a comprehensive dataset. After cleaning and organizing the data, I identified key patterns and trends.\n",
        "\n",
        "To make accurate predictions, I developed a special 'brain' for our model called a Recurrent Neural Network (RNN). This type of model is great for handling sequences of data, which is exactly what we have with hourly wind and air property measurements. RNNs excel at capturing dependencies over time, allowing us to predict power production accurately.\n",
        "\n",
        "To ensure our model works well, I divided the data into training and testing sets. I trained the RNN on the training data to help it learn the relationships between air properties, wind speed, and power production. Then, I tested the model on the testing data to measure how well it predicts power production values it hasn't seen before.\n",
        "\n",
        "For evaluation, I used a metric called Mean Squared Error (MSE) to quantify how close our predictions were to the actual power production values. Lower MSE values indicate better predictions.\n",
        "\n",
        "In the end, our model demonstrated promising results, especially for short-term forecasts. However, we encountered some challenges when making predictions far into the future due to limited historical data. If given more time, I would explore ways to gather more historical data to improve long-term predictions.\n",
        "\n",
        "Overall, this project highlights the potential of data-driven approaches in optimizing wind energy production planning. By accurately forecasting power production, we contribute to maximizing the efficiency of renewable energy resources and supporting sustainable energy practices."
      ],
      "metadata": {
        "id": "_8bepi57tOz-"
      }
    }
  ]
}